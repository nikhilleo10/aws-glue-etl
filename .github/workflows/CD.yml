name: build-and-deploy

# Controls when the action will run. Triggers the workflow on push 
# but only for the master branch.
on:
  push:
    branches: [ main ]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains two jobs called "build" and "deploy"
  build-and-deploy:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
        
      # Set up Python
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      # Install nbconvert to convert notebook file to python script
      - name: Install nbconvert
        run: |
          python -m pip install --upgrade pip
          pip install nbconvert
          sudo apt install tree

      # Convert notebook file to python
      - name: Convert notebook
        # run: jupyter nbconvert ../data-eng-updated/data-eng-etl-local.ipynb --to python 
        run: |
          cd ./data-eng-updated-new
          jupyter nbconvert data-eng-etl-local.ipynb --to python --output=data-eng-updated-new.py
          tree -a
          pwd
        
      - name: Set up AWS credentials
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_BUCKET: ${{ secrets.AWS_BUCKET }}
        run: |
          echo "AWS credentials set up"
          echo ${{ secrets.AWS_REGION }}
          echo $AWS_REGION

      - name: Upload to S3
        uses: jakejarvis/s3-sync-action@master
        with:
          args: >
            --exclude *.ipynb 
            --exclude *.json
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SOURCE_DIR: './data-eng-updated-new/'
          DEST_DIR: 'aws-scripts/'

      - name: Upload to S3
        uses: jakejarvis/s3-sync-action@master
        with:
          args: >
            --exclude *.py
            --exclude *.json
            --delete 
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          SOURCE_DIR: './data-eng-updated-new/'
          DEST_DIR: 'aws-scripts/notebooks/'
      
      # Update the Glue job to use the new script
      - name: Update Glue job
        run: |
          ./scripts/update-etl-config.sh s3://${{ secrets.AWS_BUCKET }}/glue-etl-script/data-eng-updated-new.py
      
      - name: Commit Changes
        uses: EndBug/add-and-commit@v7
        with:
          author_name: Gitflow
          author_email: nikhil.ramrakhyani@wednesday.is
          message: 'Upadated glue job properties [skip actions]'
          add: '.'
          push: false

      - name: Git pull origin
        run: |
          git pull origin ${{ github.ref }}

      - name: Pushing to a protected branch
        uses: CasperWA/push-protected@v2
        with:
          token: ${{ secrets.PAT }}
          branch: ${{ steps.vars.outputs.stage }}
          unprotect_reviews: true
