name: build-and-deploy

# Controls when the action will run. Triggers the workflow on push 
# but only for the master branch.
on:
  push:
    branches: [ main ]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains two jobs called "build" and "deploy"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
        
      # Set up Python
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      # Install nbconvert to convert notebook file to python script
      - name: Install nbconvert
        run: |
          python -m pip install --upgrade pip
          pip install nbconvert
          sudo apt install tree

      # Convert notebook file to python
      - name: Convert notebook
        # run: jupyter nbconvert ../data-eng-updated/data-eng-etl-local.ipynb --to python 
        run: |
          cd ./data-eng-updated
          jupyter nbconvert data-eng-etl-local.ipynb --to python --output=data-eng-updated-new.py
          tree -a
          pwd
        
      # Persist python script for use between jobs
      - name: Upload python script
        uses: actions/upload-artifact@v2
        with:
          name: data-eng-updated-new.py
          path: /home/runner/work/aws-glue-etl/aws-glue-etl/data-eng-updated/data-eng-updated-new.py

  # Upload python script to S3 and update Glue job
  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      - name: Download python script from build
        uses: actions/download-artifact@v2
        with:
          name: data-eng-updated-new.py
          
      # Set up credentials used by AWS CLI
      - name: Set up AWS credentials
        shell: bash
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          AWS_BUCKET: ${{ secrets.AWS_BUCKET }}
        run: |
          echo "AWS credentials set up"
          echo ${{ secrets.AWS_REGION }}
          echo $AWS_REGION


      # # Install the AWS CLI
      # - name: Install AWS CLI
      #   run: |
      #     curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
      #     unzip awscliv2.zip
      #     sudo ./aws/install

      # - name: Upload file to bucket
      #   uses: zdurham/s3-upload-github-action@master
      #   with:
      #     args: --acl public-read
      #   env:
      #     FILE: /home/runner/work/data-eng-elt-glue/data-eng-elt-glue/data-eng-updated-new.py
      #     AWS_REGION: ${{ secrets.AWS_REGION }}
      #     S3_BUCKET: ${{ secrets.AWS_BUCKET }}
      #     S3_KEY: data-eng-etl-local
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: S3 Upload Action
        id: upload # specify some ID for use in subsequent steps
        uses: hkusu/s3-upload-action@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          aws-bucket: ${{ secrets.AWS_BUCKET }}
          file-path: '/home/runner/work/aws-glue-etl/aws-glue-etl/data-eng-updated-new.py'
          output-file-url: 'true'
      - name: Show URL
        run: |
          echo '${{ steps.upload.outputs.file-url }}' # use this output
          echo ${{ secrets.PAT }}
      
      # Update the Glue job to use the new script
      - name: Update Glue job
        run: |
          echo "S3 upload URL: ${{ steps.upload.outputs.file-url }}"
          echo "PRINTING ENV VARIALBE ${{ env.S3_UPLOAD_LOCATION }}"
          echo "Output URL: ${{ steps.upload.outputs.file-url }}"
          echo "S3 Upload env varialble '$S3_UPLOAD_LOCATION'"
          ./scripts/update-etl-config.sh '${{ steps.upload.outputs.file-url }}'

      
      - name: Commit Changes
        uses: EndBug/add-and-commit@v7
        with:
          author_name: Gitflow
          author_email: nikhil.ramrakhyani@wednesday.is
          message: 'Upadated glue job properties [skip actions]'
          add: '.'
          push: false

      - name: Git pull origin
        run: |
          git pull origin ${{ github.ref }}

      - name: Pushing to a protected branch
        uses: CasperWA/push-protected@v2
        with:
          token: ${{ secrets.PAT }}
          branch: ${{ steps.vars.outputs.stage }}
          unprotect_reviews: true  